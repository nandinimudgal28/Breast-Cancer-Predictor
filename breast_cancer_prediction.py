# -*- coding: utf-8 -*-
"""Breast Cancer Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19cmC4gaW0lkRd0lv4n7o-47bHgk6PeGY
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

df = pd.read_csv('/content/breast-cancer.csv')

df.head()

df.info()
df.isnull().sum()

df['diagnosis'] = df['diagnosis'].map({'M': 0, 'B': 1})

df = df.drop(columns=['id', 'Unnamed: 32'], errors='ignore')

X = df.drop('diagnosis', axis=1)
y = df['diagnosis']

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = Sequential([
    Dense(20, input_shape=(X_train.shape[1],), activation='relu'),
    Dense(2, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(X_train_scaled, y_train, validation_split=0.1, epochs=100, batch_size=16, verbose=1)

loss, accuracy = model.evaluate(X_test_scaled, y_test)
print(f"\n Test Accuracy: {accuracy * 100:.2f}%")

plt.figure(figsize=(10,4))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title("Model Accuracy Over Epochs")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

y_pred = model.predict(X_test_scaled)
y_pred_class = (y_pred > 0.5).astype("int32")

print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_class))
print("\nClassification Report:\n", classification_report(y_test, y_pred_class))

fpr, tpr, thresholds = roc_curve(y_test, y_pred)
auc = roc_auc_score(y_test, y_pred)

plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.2f})')
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic Curve')
plt.legend()
plt.grid(True)
plt.show()

models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Random Forest': RandomForestClassifier(),
    'SVM': SVC(probability=True)
}

for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    y_proba = model.predict_proba(X_test_scaled)[:, 1]

    print(f"\n{name}")
    print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    print(f"AUC: {roc_auc_score(y_test, y_proba):.4f}")
    print(classification_report(y_test, y_pred))

from sklearn.svm import SVC

model = SVC(probability=True)
model.fit(X_train_scaled, y_train)

pip install shap

import shap
import pandas as pd

X_sample = X_test_scaled[:10]
X_sample_df = pd.DataFrame(X_sample, columns=X.columns)

def model_predict_proba_class1(X_input):
    return model.predict_proba(X_input)[:, 1]

explainer = shap.KernelExplainer(model_predict_proba_class1, X_train_scaled[:100])

shap_values = explainer.shap_values(X_sample)

print("SHAP values shape:", shap_values.shape)
print("X_sample_df shape:", X_sample_df.shape)

shap.summary_plot(shap_values, X_sample_df)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

results = {}

lr_model = LogisticRegression()
lr_model.fit(X_train_scaled, y_train)
lr_preds = lr_model.predict(X_test_scaled)
results['Logistic Regression'] = accuracy_score(y_test, lr_preds)

rf_model = RandomForestClassifier()
rf_model.fit(X_train_scaled, y_train)
rf_preds = rf_model.predict(X_test_scaled)
results['Random Forest'] = accuracy_score(y_test, rf_preds)

svm_preds = model.predict(X_test_scaled)
results['SVM'] = accuracy_score(y_test, svm_preds)

for name, acc in results.items():
    print(f"{name}: Accuracy = {acc:.4f}")

importances = rf_model.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(10, 6))
plt.title("Feature Importance (Random Forest)")
plt.bar(range(10), importances[indices[:10]], align="center")
plt.xticks(range(10), [X.columns[i] for i in indices[:10]], rotation=45)
plt.tight_layout()
plt.show()

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier

models.update({
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'Gradient Boosting': GradientBoostingClassifier(),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss')
})

for name, clf in models.items():
    clf.fit(X_train_scaled, y_train)
    preds = clf.predict(X_test_scaled)
    results[name] = accuracy_score(y_test, preds)

plt.figure(figsize=(10, 6))
plt.bar(results.keys(), results.values(), color='teal')
plt.title('Model Accuracy Comparison (Extended)')
plt.ylabel('Accuracy')
plt.ylim(0.8, 1)
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

import shap

explainer = shap.TreeExplainer(models['XGBoost'])
shap_values = explainer.shap_values(X_test_scaled)

shap.summary_plot(shap_values, pd.DataFrame(X_test_scaled, columns=X.columns))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

models = {
    'Logistic Regression': lr_model,
    'Random Forest': rf_model,
    'SVM': model
}

for name, m in models.items():
    preds = m.predict(X_test_scaled)
    cm = confusion_matrix(y_test, preds)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Benign', 'Malignant'])
    disp.plot(cmap='Blues')
    plt.title(f'Confusion Matrix: {name}')
    plt.grid(False)
    plt.show()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential()
model.add(Dense(64, input_dim=10, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.summary()

df = pd.read_csv('/content/breast-cancer.csv')

print(df.columns)
df.head()

import seaborn as sns
import matplotlib.pyplot as plt

cols_to_drop = [col for col in ['id', 'diagnosis'] if col in df.columns]
df_numeric = df.drop(columns=cols_to_drop)

# Compute correlation matrix
corr = df_numeric.corr()

# Plot heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(corr, annot=False, cmap='coolwarm', linewidths=0.5)
plt.title('Feature Correlation Heatmap (Breast Cancer Dataset)')
plt.tight_layout()
plt.show()

from sklearn.metrics import roc_curve, auc

plt.figure(figsize=(8, 6))

for name, m in models.items():
    probs = m.predict_proba(X_test_scaled)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, probs)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.title('ROC Curve Comparison')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

df['mean_symmetry'] = (df['symmetry_mean'] + df['symmetry_worst']) / 2
df['concavity_ratio'] = df['concavity_mean'] / (df['radius_mean'] + 1e-5)
df['area_ratio'] = df['area_se'] / (df['area_mean'] + 1e-5)
df['texture_to_radius'] = df['texture_mean'] / (df['radius_mean'] + 1e-5)

def safe_create_feature(df, name, func):
    try:
        df[name] = func(df)
    except:
        print(f"Skipped: {name} (missing columns)")

safe_create_feature(df, 'radius_area_ratio', lambda d: d['radius_mean'] / (d['area_mean'] + 1e-5))
safe_create_feature(df, 'concavity_radius_ratio', lambda d: d['concavity_mean'] / (d['radius_mean'] + 1e-5))
safe_create_feature(df, 'compactness_texture_ratio', lambda d: d['compactness_mean'] / (d['texture_mean'] + 1e-5))

safe_create_feature(df, 'area_worst_diff', lambda d: d['area_worst'] - d['area_mean'])
safe_create_feature(df, 'symmetry_change', lambda d: d['symmetry_worst'] - d['symmetry_mean'])

safe_create_feature(df, 'mean_smoothness_avg', lambda d: (d['smoothness_mean'] + d['smoothness_worst']) / 2)
safe_create_feature(df, 'mean_fractal_dimension', lambda d: (d['fractal_dimension_mean'] + d['fractal_dimension_worst']) / 2)

safe_create_feature(df, 'total_texture', lambda d: d['texture_mean'] + d['texture_worst'] + d['texture_se'])
safe_create_feature(df, 'shape_severity', lambda d: d['compactness_worst'] + d['concave_points_worst'])

print(f"New shape after feature engineering: {df.shape}")
df.head()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(16, 12))
corr_matrix = df.select_dtypes(include='number').corr()
sns.heatmap(corr_matrix, cmap='coolwarm', center=0, linewidths=0.5)
plt.title('Correlation Heatmap After Feature Engineering')
plt.tight_layout()
plt.show()

def safe_feature(df, name, func):
    try:
        df[name] = func(df)
    except:
        print(f"Skipped: {name} (missing required columns)")

safe_feature(df, 'area_to_radius', lambda d: d['area_mean'] / (d['radius_mean'] + 1e-5))
safe_feature(df, 'texture_to_radius', lambda d: d['texture_mean'] / (d['radius_mean'] + 1e-5))
safe_feature(df, 'concavity_to_compactness', lambda d: d['concavity_mean'] / (d['compactness_mean'] + 1e-5))
safe_feature(df, 'symmetry_to_smoothness', lambda d: d['symmetry_mean'] / (d['smoothness_mean'] + 1e-5))

safe_feature(df, 'radius_range', lambda d: d['radius_worst'] - d['radius_mean'])
safe_feature(df, 'area_range', lambda d: d['area_worst'] - d['area_mean'])
safe_feature(df, 'texture_range', lambda d: d['texture_worst'] - d['texture_mean'])
safe_feature(df, 'concave_points_range', lambda d: d['concave_points_worst'] - d['concave_points_mean'])

safe_feature(df, 'total_symmetry', lambda d: d['symmetry_mean'] + d['symmetry_worst'] + d['symmetry_se'])
safe_feature(df, 'total_fractal', lambda d: d['fractal_dimension_mean'] + d['fractal_dimension_worst'])
safe_feature(df, 'shape_severity', lambda d: d['compactness_worst'] + d['concave_points_worst'])

safe_feature(df, 'avg_texture', lambda d: (d['texture_mean'] + d['texture_worst']) / 2)
safe_feature(df, 'avg_radius', lambda d: (d['radius_mean'] + d['radius_worst']) / 2)
safe_feature(df, 'avg_area', lambda d: (d['area_mean'] + d['area_worst']) / 2)
safe_feature(df, 'avg_concavity', lambda d: (d['concavity_mean'] + d['concavity_worst']) / 2)

safe_feature(df, 'asymmetry_index', lambda d: (d['symmetry_worst'] - d['symmetry_mean']) / (d['symmetry_mean'] + 1e-5))
safe_feature(df, 'fractal_ratio', lambda d: d['fractal_dimension_mean'] / (d['fractal_dimension_worst'] + 1e-5))
safe_feature(df, 'complicated_shape', lambda d: d['concavity_worst'] * d['compactness_worst'])

print(f" Total features after engineering: {df.shape[1]}")
df.head()

X = df.drop(columns=['diagnosis', 'id']) if 'id' in df.columns else df.drop(columns=['diagnosis'])
y = df['diagnosis']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.preprocessing import LabelEncoder

if y.dtype == 'object' or y.dtype == 'str':
    le = LabelEncoder()
    y = le.fit_transform(y)  # 'B' -> 0, 'M' -> 1

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

for name, clf in models.items():
    clf.fit(X_train_scaled, y_train)
    preds = clf.predict(X_test_scaled)
    results[name] = accuracy_score(y_test, preds)

from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

# Use a basic classifier for RFE (RandomForestClassifier or LogisticRegression works well)
estimator = LogisticRegression(max_iter=1000)

# Perform RFE to select top N features
n_features_to_select = 10  # Feel free to change to 15, 20, etc.
rfe = RFE(estimator, n_features_to_select=n_features_to_select)
rfe.fit(X_train_scaled, y_train)

selected_features = X.columns[rfe.support_]
ranking = rfe.ranking_

print(" Top selected features by RFE:")
for feat in selected_features:
    print(f"• {feat}")

X_train_rfe = rfe.transform(X_train_scaled)
X_test_rfe = rfe.transform(X_test_scaled)

xgb_rfe = models['XGBoost']
xgb_rfe.fit(X_train_rfe, y_train)
preds_rfe = xgb_rfe.predict(X_test_rfe)

from sklearn.metrics import accuracy_score
acc_rfe = accuracy_score(y_test, preds_rfe)
print(f"\n Accuracy using top {n_features_to_select} RFE-selected features: {acc_rfe:.4f}")

import matplotlib.pyplot as plt
import pandas as pd

ranking_df = pd.DataFrame({
    'Feature': X.columns,
    'Ranking': ranking
}).sort_values(by='Ranking')

plt.figure(figsize=(10, 6))
sns.barplot(x='Ranking', y='Feature', data=ranking_df, palette='magma')
plt.title('RFE Feature Rankings (Lower is Better)')
plt.show()

import shap
import pandas as pd

explainer = shap.TreeExplainer(models['XGBoost'])

X_test_rfe_df = pd.DataFrame(X_test_rfe, columns=selected_features)

shap_values = explainer.shap_values(X_test_rfe_df)

shap.summary_plot(shap_values, X_test_rfe_df, plot_type='bar', show=True)

shap.summary_plot(shap_values, X_test_rfe_df)

pd.Series(selected_features).to_csv("top_features_rfe.csv", index=False)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train[selected_features])

def predict_cancer(model, scaler, feature_names):
    print("\n Breast Cancer Prediction Tool")
    print("Enter the following features:")

    input_data = []
    for feature in feature_names:
        try:
            val = float(input(f"  ➤ {feature}: "))
            input_data.append(val)
        except:
            print(f" Invalid input for {feature}. Please enter numeric value.")
            return

    input_data_scaled = scaler.transform([input_data])
    prediction = model.predict(input_data_scaled)[0]

    result = " Malignant (Cancerous)" if prediction == 1 else " Benign (Non-Cancerous)"
    print("\n Prediction:", result)

# 🔁 Example usage with final model & top features
predict_cancer(model=final_model, scaler=scaler, feature_names=selected_features)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
import joblib

# 1.  Load your dataset
df = pd.read_csv("/content/breast-cancer.csv")

# 2.  Encode target column
le = LabelEncoder()
df["diagnosis"] = le.fit_transform(df["diagnosis"])  # M=1, B=0

# 3.  Use 10 selected features only
selected_features = [
    "concave points_mean", "radius_se", "symmetry_se",
    "radius_worst", "texture_worst", "concave points_worst",
    "area_mean", "area_worst", "compactness_mean", "smoothness_mean"
]

X = df[selected_features]
y = df["diagnosis"]

# 4.  Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 5. 🔀 Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# 6.  Train model
final_model = RandomForestClassifier(random_state=42)
final_model.fit(X_train, y_train)

# 7.  Save both model and scaler
joblib.dump(final_model, "final_model.pkl")
joblib.dump(scaler, "scaler.pkl")

print(" Model and Scaler saved successfully.")

final_model = models['XGBoost']
final_model.fit(X_train_rfe, y_train)
final_preds = final_model.predict(X_test_rfe)
final_proba = final_model.predict_proba(X_test_rfe)[:, 1]

# ✅ Accuracy and classification report
print(" Final Model Accuracy:", accuracy_score(y_test, final_preds))
print("\n Classification Report:")
print(classification_report(y_test, final_preds, target_names=['Benign', 'Malignant']))

# ✅ Confusion Matrix
cm = confusion_matrix(y_test, final_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Benign', 'Malignant'])
disp.plot(cmap='Blues')
plt.title(" Final Model: Confusion Matrix")
plt.grid(False)
plt.show()

# ✅ ROC-AUC Score
roc_score = roc_auc_score(y_test, final_proba)
print(f" ROC-AUC Score: {roc_score:.4f}")

# ✅ Final SHAP Plot (for interpretability)
shap.summary_plot(shap_values, X_test_rfe_df, plot_type='bar', show=True)

# ✅ Final Message
from IPython.display import Markdown
Markdown("""
##  Project Conclusion

This project successfully demonstrates the application of Machine Learning for Breast Cancer Prediction using:

-  Real-world data (Wisconsin Breast Cancer Dataset)
-  Domain-driven feature engineering (20+ features created)
-  Model comparison (LogReg, SVM, RF, XGBoost, etc.)
-  Recursive Feature Elimination (RFE) for optimal subset
-  Model explainability with SHAP
-  Evaluation using Accuracy, Confusion Matrix, ROC-AUC

This pipeline reflects a production-grade approach to healthcare ML, emphasizing **accuracy, interpretability, and simplicity**.
""")







